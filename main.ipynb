{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your Facebook credentials (only used if cookies aren't saved yet)\n",
    "FB_EMAIL = \"supergofai@yahoo.com.hk\"\n",
    "FB_PASSWORD = \"hkopenf095836\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cookies...\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Facebook credentials and group URL (update with your details)\n",
    "\n",
    "GROUP_URL = \"https://www.facebook.com/groups/1982935245273808/?sorting_setting=CHRONOLOGICAL\"\n",
    "COOKIES_FILE = \"fb_cookies.pkl\"\n",
    "\n",
    "# A queue for image URLs (for later processing)\n",
    "image_queue = []\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "def human_delay(a=2, b=4):\n",
    "    time.sleep(random.uniform(a, b))\n",
    "\n",
    "def download_image(image_url):\n",
    "    \"\"\"Download an image from image_url to a temporary file and return its file path.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\")\n",
    "            temp_file.write(response.content)\n",
    "            temp_file.close()\n",
    "            return temp_file.name\n",
    "        else:\n",
    "            print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error downloading image:\", e)\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# Analysis Function using Ollama with English Prompt\n",
    "# -------------------------------\n",
    "\n",
    "def analyze_post(text, image_url, post_time):\n",
    "    \"\"\"\n",
    "    Use Ollama's Llama-3.2-Vision model to analyze the post.\n",
    "    The prompt instructs the model (in English) to extract:\n",
    "      - station: The brand or name of the gas station (if mentioned); else null.\n",
    "      - intersection: The road or intersection mentioned (e.g. an address); else null.\n",
    "      - gps: If GPS coordinates (formatted as \"lat,lon\") can be inferred from the intersection, return them; else null.\n",
    "      - line_flag: true if the post indicates there is a queue/line; otherwise false.\n",
    "      - oil_truck_flag: true if the post mentions an oil truck is present; otherwise false.\n",
    "      - time_since_start: \"current\" if the event has just begun or updated comments indicate a recent change; otherwise a time offset or \"unknown\".\n",
    "      - gas_price: The per-unit gas price as seen in the image; if not visible or inferable, \"unknown\".\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are an expert tasked with extracting gas station information from social media posts.\n",
    "You must respond with a JSON object ONLY, with no additional commentary or markdown formatting.\n",
    "\n",
    "Extract the following fields:\n",
    "- \"station\": The brand or name of the gas station mentioned in the post (if any); otherwise null.\n",
    "- \"intersection\": The road or intersection mentioned (e.g. an address or intersection); if not mentioned, null.\n",
    "- \"gps\": If GPS coordinates (formatted as \"lat,lon\") can be inferred from the intersection, return them; otherwise null.\n",
    "- \"line_flag\": true if the post indicates there is a queue/line; otherwise false.\n",
    "- \"oil_truck_flag\": true if the post mentions an oil truck is present; otherwise false.\n",
    "- \"time_since_start\": If the text indicates that the event has just begun (e.g. \"the staff just put on the sticker\") or is updated by comments showing a change (e.g. \"back to normal\" or \"out of gas\"), return \"current\" or a time offset if mentioned; otherwise \"unknown\".\n",
    "- \"gas_price\": The per-unit gas price as seen in the image. If not directly visible or inferable, return \"unknown\".\n",
    "\n",
    "Input details:\n",
    "- Post time: \"{post_time}\"\n",
    "- Post text: \"{text}\"\n",
    "- Image: Provided below (if available).\n",
    "\n",
    "Please return only a valid JSON object with the fields described above.\n",
    "\"\"\"\n",
    "    # Print out the input prompt for debugging.\n",
    "    print(\"\\n=== Input Prompt to Ollama ===\")\n",
    "    print(prompt)\n",
    "    \n",
    "    # Download image locally if an image URL is provided.\n",
    "    local_image_path = None\n",
    "    if image_url:\n",
    "        local_image_path = download_image(image_url)\n",
    "\n",
    "    try:\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }]\n",
    "        if local_image_path:\n",
    "            messages[0][\"images\"] = [local_image_path]\n",
    "        \n",
    "        response = ollama.chat(model=\"llama3.2-vision\", messages=messages, options={\"temperature\": 0})\n",
    "        \n",
    "        # Debug: print the raw response from Ollama.\n",
    "        print(\"\\n=== Raw Ollama Response ===\")\n",
    "        print(response)\n",
    "        \n",
    "        # Now, retrieve the JSON string from response.message.content.\n",
    "        raw_output = \"\"\n",
    "        if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "            raw_output = response[\"message\"][\"content\"].strip()\n",
    "        \n",
    "        if not raw_output:\n",
    "            print(\"Empty output from Ollama model.\")\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            result = json.loads(raw_output)\n",
    "        except json.JSONDecodeError as je:\n",
    "            print(\"JSON decoding error:\", je)\n",
    "            print(\"Model output was:\")\n",
    "            print(raw_output)\n",
    "            result = {}\n",
    "    except Exception as e:\n",
    "        print(\"Error calling or parsing response from Ollama model:\", e)\n",
    "        result = {}\n",
    "    finally:\n",
    "        if local_image_path and os.path.exists(local_image_path):\n",
    "            os.remove(local_image_path)\n",
    "    return result\n",
    "\n",
    "# -------------------------------\n",
    "# Main Scraping Code: Collect All Posts Then Batch Process\n",
    "# -------------------------------\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "# Uncomment for headless mode:\n",
    "options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "actions = ActionChains(driver)\n",
    "\n",
    "# List to store all posts' data\n",
    "posts_data = []\n",
    "\n",
    "try:\n",
    "    # 1. Navigate to Facebook to set cookie domain.\n",
    "    driver.get(\"https://www.facebook.com/\")\n",
    "    human_delay(2, 3)\n",
    "\n",
    "    # 2. Load cookies if available.\n",
    "    if os.path.exists(COOKIES_FILE):\n",
    "        print(\"Loading cookies...\")\n",
    "        with open(COOKIES_FILE, \"rb\") as f:\n",
    "            cookies = pickle.load(f)\n",
    "        for cookie in cookies:\n",
    "            if 'sameSite' in cookie and cookie['sameSite'] == 'None':\n",
    "                cookie['sameSite'] = 'Strict'\n",
    "            try:\n",
    "                driver.add_cookie(cookie)\n",
    "            except Exception as e:\n",
    "                print(\"Error adding cookie:\", e)\n",
    "        driver.refresh()\n",
    "        human_delay(3, 5)\n",
    "    else:\n",
    "        print(\"No cookies found. Logging in manually...\")\n",
    "        email_input = driver.find_element(By.ID, \"email\")\n",
    "        password_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input.send_keys(FB_EMAIL)\n",
    "        human_delay(1, 2)\n",
    "        password_input.send_keys(FB_PASSWORD)\n",
    "        human_delay(1, 2)\n",
    "        password_input.send_keys(Keys.RETURN)\n",
    "        human_delay(5, 7)\n",
    "        input(\"Complete any 2FA in the browser, then press Enter to continue...\")\n",
    "        cookies = driver.get_cookies()\n",
    "        with open(COOKIES_FILE, \"wb\") as f:\n",
    "            pickle.dump(cookies, f)\n",
    "        print(\"Cookies saved for future sessions.\")\n",
    "\n",
    "    # 3. Navigate to the target Facebook group.\n",
    "    driver.get(GROUP_URL)\n",
    "    human_delay(5, 7)\n",
    "\n",
    "    # 4. Slowly scroll to load posts.\n",
    "    for _ in range(3):\n",
    "        current_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_increment = random.randint(300, 800)\n",
    "        for pos in range(0, current_height, scroll_increment):\n",
    "            driver.execute_script(\"window.scrollTo(0, arguments[0]);\", pos)\n",
    "            human_delay(0.2, 0.5)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        human_delay(3, 5)\n",
    "\n",
    "    # 5. Locate post containers.\n",
    "    posts = driver.find_elements(By.XPATH, \"//div[@role='article']\")\n",
    "    print(f\"Found {len(posts)} posts.\")\n",
    "\n",
    "    # For development, we collect only the first 10 posts.\n",
    "    posts = posts[:1]\n",
    "    print(f\"Collecting only the first {len(posts)} posts for development.\")\n",
    "\n",
    "    # 6. Extract data from each post and store in posts_data.\n",
    "    for i in range(len(posts)):\n",
    "        attempts = 0\n",
    "        post_info = {\"text\": \"\", \"image_urls\": [], \"post_time\": \"\"}\n",
    "        while attempts < 3:\n",
    "            try:\n",
    "                # Re-fetch posts to avoid stale element issues.\n",
    "                posts = driver.find_elements(By.XPATH, \"//div[@role='article']\")\n",
    "                post = posts[i]\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", post)\n",
    "                human_delay(1, 2)\n",
    "\n",
    "                # Expand \"See More\" if available.\n",
    "                try:\n",
    "                    more_links = post.find_elements(By.XPATH, \".//a[contains(text(), 'See More')]\")\n",
    "                    if more_links:\n",
    "                        actions.move_to_element(more_links[0]).perform()\n",
    "                        human_delay(0.5, 1)\n",
    "                        driver.execute_script(\"arguments[0].click();\", more_links[0])\n",
    "                        human_delay(2, 3)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error clicking 'See More' in post {i+1}: {e}\")\n",
    "\n",
    "                # Get post text.\n",
    "                post_text = driver.execute_script(\"return arguments[0].innerText;\", post)\n",
    "                post_info[\"text\"] = post_text.strip() if post_text.strip() else \"\"\n",
    "                \n",
    "                # For demonstration, we use a placeholder for post time.\n",
    "                post_info[\"post_time\"] = \"10 hours ago\"  # Replace with actual extraction logic as needed.\n",
    "\n",
    "                # Extract image URLs.\n",
    "                try:\n",
    "                    img_tags = post.find_elements(By.XPATH, \".//img\")\n",
    "                    image_urls = []\n",
    "                    if img_tags:\n",
    "                        for img in img_tags:\n",
    "                            src = img.get_attribute(\"src\")\n",
    "                            if src and src not in image_queue:\n",
    "                                image_queue.append(src)\n",
    "                                image_urls.append(src)\n",
    "                    post_info[\"image_urls\"] = image_urls\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting images in post {i+1}: {e}\")\n",
    "\n",
    "                # Debug: Print snippet of post text and inner HTML.\n",
    "                inner_html = post.get_attribute(\"innerHTML\")\n",
    "                print(f\"\\n=== Post {i+1} ===\")\n",
    "                print(\"Post text:\")\n",
    "                print(post_info[\"text\"] if post_info[\"text\"] else \"(No text found)\")\n",
    "                print(\"Inner HTML snippet:\")\n",
    "                print(inner_html[:300] + \"...\" if len(inner_html) > 300 else inner_html)\n",
    "                break  # Successfully extracted post info.\n",
    "            except StaleElementReferenceException:\n",
    "                print(f\"StaleElementReferenceException encountered in post {i+1}. Retrying...\")\n",
    "                human_delay(1, 2)\n",
    "                attempts += 1\n",
    "        else:\n",
    "            print(f\"Failed to process post {i+1} after several retries.\")\n",
    "        \n",
    "        posts_data.append(post_info)\n",
    "\n",
    "    print(\"\\n=== Finished collecting post data ===\")\n",
    "    print(f\"Total posts collected: {len(posts_data)}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Batch Process Posts using Ollama\n",
    "    # -------------------------------\n",
    "    print(\"\\n=== Batch processing posts (using Ollama) ===\")\n",
    "    analysis_results = []\n",
    "    for idx, post in enumerate(posts_data, start=1):\n",
    "        # For image analysis, take the first image URL if available.\n",
    "        image_url = post[\"image_urls\"][0] if post[\"image_urls\"] else None\n",
    "        analysis = analyze_post(post[\"text\"], image_url, post[\"post_time\"])\n",
    "        analysis_results.append(analysis)\n",
    "        print(f\"\\n=== Analysis result for post {idx} ===\")\n",
    "        print(json.dumps(analysis, indent=2, ensure_ascii=False))\n",
    "        human_delay(2, 4)\n",
    "\n",
    "    # Optionally, display the full image queue.\n",
    "    print(\"\\n=== Image Queue (for later processing) ===\")\n",
    "    for idx, url in enumerate(image_queue, start=1):\n",
    "        print(f\"{idx}. {url}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert tasked with extracting gas station information from social media posts.\n",
    "You must respond with a JSON object ONLY, with no additional commentary or markdown formatting.\n",
    "\n",
    "Extract the following fields:\n",
    "- \"location\": If the post text mentions a location (e.g. an address or intersection), return it; else null.\n",
    "- \"gps\": If GPS coordinates (formatted as \"lat,lon\") can be inferred, return them; else null.\n",
    "- \"line_flag\": true if the post indicates there is a queue/line; otherwise false.\n",
    "- \"oil_truck_flag\": true if the post mentions an oil truck is present; otherwise false.\n",
    "- \"time_since_start\": If the text indicates that the event has just begun (e.g. \"the staff just put on the sticker\"), return \"current\". If a time offset is mentioned, return that value; else \"unknown\".\n",
    "- \"gas_price\": The per-unit gas price. If not visible or inferable, return \"unknown\".\n",
    "\n",
    "Input details:\n",
    "- Post time: \"10 hours ago\"\n",
    "- Post text: \"Humraj Singh\n",
    "Gurman Dhindsa\n",
    "2小時\n",
    " \n",
    " · \n",
    "Bramalea and Peter Robertson Petro in Brampton\n",
    "所有心情：\n",
    "5\n",
    "5\n",
    "3個回應\n",
    "讚好\n",
    "回應\n",
    "傳送\n",
    "查看更多回應\n",
    "Rai Quan\n",
    "No gas available.\n",
    "2小時\n",
    "讚好\n",
    "回覆\n",
    "2\n",
    "Humraj Singh\n",
    "Dont come they have no gas\n",
    "1小時\n",
    "讚好\n",
    "回覆\"\n",
    "\n",
    "If an image is provided, use it to help extract the gas price.\n",
    "Return only a valid JSON object.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_link  = \"https://scontent-yyz1-1.xx.fbcdn.net/v/t39.30808-6/481478506_10233214677856295_4449808216704385674_n.jpg?stp=cp6_dst-jpegr_p526x296_tt6&_nc_cat=110&ccb=1-7&_nc_sid=aa7b47&_nc_ohc=KczbmWSByakQ7kNvgHFlwSF&_nc_oc=AdiynByPy9TZM0pCpN6pJ3C_zhM73O5sRut_oGXIs9wqZMDhDqIBe2hA8J06-e53JzI&_nc_zt=23&se=-1&_nc_ht=scontent-yyz1-1.xx&_nc_gid=AttlxX2sc-S58_aDQQsj5Wo&oh=00_AYCaeB-ajBhDu7bssX98KZ3Y-GBtF5wAScnIv66azJs9jg&oe=67C3FC47\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_text = \"\"\"Gurman Dhindsa\n",
    "2小時\n",
    " \n",
    " · \n",
    "Bramalea and Peter Robertson Petro in Brampton\n",
    "所有心情：\n",
    "5\n",
    "5\n",
    "3個回應\n",
    "讚好\n",
    "回應\n",
    "傳送\n",
    "查看更多回應\n",
    "Rai Quan\n",
    "No gas available.\n",
    "2小時\n",
    "讚好\n",
    "回覆\n",
    "2\n",
    "Humraj Singh\n",
    "Dont come they have no gas\n",
    "1小時\n",
    "讚好\n",
    "回覆\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Input Prompt to Ollama ===\n",
      "You are an expert tasked with extracting gas station information from social media posts.\n",
      "You must respond with a JSON object ONLY, with no additional commentary or markdown formatting.\n",
      "\n",
      "Extract the following fields:\n",
      "- \"location\": If the post text mentions a location (e.g. an address or intersection), return it; else null.\n",
      "- \"gps\": If GPS coordinates (formatted as \"lat,lon\") can be inferred, return them; else null.\n",
      "- \"line_flag\": true if the post indicates there is a queue/line; otherwise false.\n",
      "- \"oil_truck_flag\": true if the post mentions an oil truck is present; otherwise false.\n",
      "- \"time_since_start\": If the text indicates that the event has just begun (e.g. \"the staff just put on the sticker\"), return \"current\". If a time offset is mentioned, return that value; else \"unknown\".\n",
      "- \"gas_price\": The per-unit gas price. If not visible or inferable, return \"unknown\".\n",
      "\n",
      "Input details:\n",
      "- Post time: \"10 hours ago\"\n",
      "- Post text: \"Gurman Dhindsa\n",
      "2小時\n",
      " \n",
      " · \n",
      "Bramalea and Peter Robertson Petro in Brampton\n",
      "所有心情：\n",
      "5\n",
      "5\n",
      "3個回應\n",
      "讚好\n",
      "回應\n",
      "傳送\n",
      "查看更多回應\n",
      "Rai Quan\n",
      "No gas available.\n",
      "2小時\n",
      "讚好\n",
      "回覆\n",
      "2\n",
      "Humraj Singh\n",
      "Dont come they have no gas\n",
      "1小時\n",
      "讚好\n",
      "回覆\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "以 Kevin Lam 的身分回應\"\n",
      "- Image: Provided below (if available).\n",
      "\n",
      "Please return only the JSON object with the fields described above.\n",
      "\n",
      "\n",
      "=== Raw Ollama Response ===\n",
      "model='llama3.2-vision' created_at='2025-02-25T22:48:11.2230219Z' done=True done_reason='stop' total_duration=46857919300 load_duration=13945723600 prompt_eval_count=357 prompt_eval_duration=21319000000 eval_count=33 eval_duration=11311000000 message=Message(role='assistant', content='{\"location\":null,\"gps\":null,\"line_flag\":false,\"oil_truck_flag\":false,\"time_since_start\":\"unknown\",\"gas_price\":\"unknown\"}', images=None, tool_calls=None)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "analysis = analyze_post(post_text, image_link, \"10 hours ago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"location\": null,\\n  \"gps\": null,\\n  \"line_flag\": false,\\n  \"oil_truck_flag\": false,\\n  \"time_since_start\": \"unknown\",\\n  \"gas_price\": \"unknown\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
